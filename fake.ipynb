{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74593c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_11428\\4143196359.py:11: DeprecationWarning: Importing clear_output from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output, display\n",
      "C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_11428\\4143196359.py:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output, display\n",
      "Exception when trying to get git hash... bad!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read entry c4bab4322e01468ee8e99343344a7a02 hit\n",
      "[prepare]: started processing a df output_fake_1000.tsv with 45652 rows:\n",
      "read entry 27d82359f97e6ab3f74db5dedb1771fd hit\n",
      "[prepare] finished\n",
      "[prepare] loading your model(s)...\n",
      "[prepare] finished loading your model(s)...\n",
      "[build_all_tracks] start\n",
      "read entry 55bb202a014c463f0ccc979712d5f0ea hit\n",
      "read entry ce07df513497c2c64c12b6f3bc0d0c01 hit\n",
      "\n",
      "\n",
      "processed: 199: 100%|████████████████████████████████████████████████████████████████| 200/200 [00:10<00:00, 19.45it/s]\n",
      "[build_all_tracks] cache miss, finish\n",
      "[run model] start\n",
      "read entry 9032c58e45262bcf5beaf10fb491317e hit\n",
      "read entry 01b5aa180fccf188525f1326806d4fa7 hit\n",
      "\n",
      "\n",
      "processed: 168:  84%|██████████████████████████████████████████████████████          | 169/200 [12:51<02:00,  3.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DropEmpty returned empty data. Skipping all further transforms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got exception for preprocessing:\n",
      " message=Traceback (most recent call last):\n",
      "  File \"D:\\ariadne_master_clean\\ariadne-master\\eval\\event_evaluation.py\", line 122, in run_model\n",
      "    preprocess_result = model_preprocess_func(event_df)\n",
      "  File \"C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_11428\\4143196359.py\", line 133, in get_graph\n",
      "    event = event[['event', 'r', 'phi', 'z', 'station', 'track']]\n",
      "  File \"D:\\miniconda\\envs\\ariadne_cpu\\lib\\site-packages\\pandas\\core\\frame.py\", line 3511, in __getitem__\n",
      "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
      "  File \"D:\\miniconda\\envs\\ariadne_cpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5782, in _get_indexer_strict\n",
      "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
      "  File \"D:\\miniconda\\envs\\ariadne_cpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5845, in _raise_if_missing\n",
      "    raise KeyError(f\"{not_found} not in index\")\n",
      "KeyError: \"['r', 'phi'] not in index\"\n",
      " \n",
      "                                            on \n",
      "event_id=168\n",
      "processed: 199: 100%|████████████████████████████████████████████████████████████████| 200/200 [14:55<00:00,  4.48s/it]\n",
      "[run model] cache miss, finish\n",
      "[solve results] start\n",
      "[solve results] finish\n",
      "[solve results] final stats:\n",
      "==========EVALUATION RESULTS==========\n",
      "Total events evaluated: 200\n",
      "Total tracks evaluated: 986\n",
      "Track Efficiency (recall): 0.2485 \n",
      "Track Purity (precision): 0.9761 \n",
      "Fully reconstructed event ratio: 0.1750\n",
      "Mean cpu time per event: 4.4706 sec (0.22 events per second) \n",
      "Mean gpu time per event: 0.0207 sec (48.33 events per second) \n",
      "==========EVALUATION RESULTS==========\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from IPython.core.display import clear_output, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "from eval.event_evaluation import EventEvaluator\n",
    "from ariadne_v2.transformations import Compose, ConstraintsNormalize, ToCylindrical, DropSpinningTracks, DropShort, \\\n",
    "    DropEmpty\n",
    "\n",
    "parse_cfg = {\n",
    "    'csv_params': {\n",
    "        \"sep\": '\\s+',\n",
    "        # \"nrows\": 15000,\n",
    "        \"encoding\": 'utf-8',\n",
    "        \"names\": ['event', 'x', 'y', 'z', 'station', 'track', 'px', 'py', 'pz', 'X0', 'Y0', 'Z0']\n",
    "    },\n",
    "\n",
    "    'input_file_mask': \"D:/ariadne-master/output_fake_1000.tsv\",\n",
    "    'events_quantity': '0..200'\n",
    "}\n",
    "\n",
    "global_transformer = Compose([\n",
    "    DropSpinningTracks(),\n",
    "    DropShort(num_stations=3),\n",
    "    DropEmpty()\n",
    "])\n",
    "\n",
    "import scripts.clean_cache\n",
    "\n",
    "# to clean cache if needed\n",
    "# scripts.clean_cache.clean_jit_cache('20d')\n",
    "\n",
    "\n",
    "from ariadne.graph_net.graph_utils.graph_prepare_utils import to_pandas_graph_from_df, get_pd_line_graph, \\\n",
    "    apply_nodes_restrictions, apply_edge_restriction, construct_output_graph\n",
    "from ariadne.transformations import Compose, ConstraintsNormalize, ToCylindrical\n",
    "\n",
    "from ariadne_v2.inference import IModelLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "suff_df = ('_p', '_c')\n",
    "gin.bind_parameter('get_pd_line_graph.restrictions_0', (-2., 2.))\n",
    "gin.bind_parameter('get_pd_line_graph.restrictions_1', (-0.03, 0.03))\n",
    "gin.bind_parameter('get_pd_line_graph.suffix_c', '_c')\n",
    "gin.bind_parameter('get_pd_line_graph.suffix_p', '_p')\n",
    "gin.bind_parameter('get_pd_line_graph.spec_kwargs', {'suffix_c': '_c',\n",
    "                                                     'suffix_p': '_p',\n",
    "                                                     'axes': ['r', 'phi', 'z']})\n",
    "_edge_restriction = 0.15\n",
    "\n",
    "\n",
    "class GraphModelLoader(IModelLoader):\n",
    "    def __call__(self):\n",
    "        from ariadne.graph_net.model import GraphNet_v1\n",
    "        import torch\n",
    "\n",
    "        gin.bind_parameter('GraphNet_v1.input_dim', 5)\n",
    "        gin.bind_parameter('GraphNet_v1.hidden_dim', 128)\n",
    "        gin.bind_parameter('GraphNet_v1.n_iters', 1)\n",
    "\n",
    "        def weights_update_g(model, checkpoint):\n",
    "            model_dict = model.state_dict()\n",
    "            pretrained_dict = checkpoint['state_dict']\n",
    "            real_dict = {}\n",
    "            for (k, v) in model_dict.items():\n",
    "                needed_key = None\n",
    "                for pretr_key in pretrained_dict:\n",
    "                    if k in pretr_key:\n",
    "                        needed_key = pretr_key\n",
    "                        break\n",
    "                assert needed_key is not None, \"key %s not in pretrained_dict %r!\" % (k, pretrained_dict.keys())\n",
    "                real_dict[k] = pretrained_dict[needed_key]\n",
    "\n",
    "            model.load_state_dict(real_dict)\n",
    "            model.eval()\n",
    "            return model\n",
    "\n",
    "        path_g =  'D:/ariadne-master/lightning_logs/GraphNet_v1/version_120/epoch=19-step=3999.ckpt'\n",
    "\n",
    "        checkpoint_g = torch.load(path_g) if torch.cuda.is_available() else torch.load(path_g,\n",
    "                                                                                       map_location=torch.device('cpu'))\n",
    "        model_g = weights_update_g(model=GraphNet_v1(),\n",
    "                                   checkpoint=checkpoint_g)\n",
    "        model_hash = {\"path_g\": path_g, 'gin': gin.config_str(), 'model': '%r' % model_g, 'edge': _edge_restriction}\n",
    "        return model_hash, model_g\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "GraphWithIndices = namedtuple('Graph', ['X', 'Ri', 'Ro', 'y', 'v1v2v3', 'ev_id'])\n",
    "\n",
    "\n",
    "transformer_g = Compose([\n",
    "    DropSpinningTracks(),\n",
    "    DropShort(),\n",
    "    DropEmpty(),\n",
    "    ToCylindrical(),\n",
    "    ConstraintsNormalize(\n",
    "        columns=('r', 'phi', 'z'),\n",
    "        constraints={'r': [269., 581.], 'phi': [-3.15, 3.15], 'z': [-2386.0, 2386.0]},\n",
    "        use_global_constraints=True\n",
    "    ),\n",
    "])\n",
    "\n",
    "def construct_graph_with_indices(graph, v1v2v3, ev_id):\n",
    "    return GraphWithIndices(graph.X, graph.Ri, graph.Ro, graph.y, v1v2v3, ev_id)\n",
    "\n",
    "\n",
    "def get_graph(event):\n",
    "    event = event[['event', 'x', 'y', 'z', 'station', 'track', 'index_old']]\n",
    "\n",
    "    try:\n",
    "        event = transformer_g(event)\n",
    "    except AssertionError as err:\n",
    "        print(\"ASS error %r\" % err)\n",
    "        return None\n",
    "\n",
    "    event.index = event['index_old'].values\n",
    "    event = event[['event', 'r', 'phi', 'z', 'station', 'track']]\n",
    "\n",
    "    G = to_pandas_graph_from_df(event, suffixes=suff_df, compute_is_true_track=True)\n",
    "\n",
    "    nodes_t, edges_t = get_pd_line_graph(G, apply_nodes_restrictions)\n",
    "\n",
    "    edges_filtered = apply_edge_restriction(edges_t, edge_restriction=_edge_restriction)\n",
    "    graph = construct_output_graph(nodes_t, edges_filtered, ['y_p', 'y_c', 'z_p', 'z_c', 'z'],\n",
    "                                   [np.pi, np.pi, 1., 1., 1.], 'edge_index_p', 'edge_index_c')\n",
    "    ev_id = event.event.values[0]\n",
    "    graph_with_inds = construct_graph_with_indices(graph,\n",
    "                                                   edges_filtered[['from_ind', 'cur_ind', 'to_ind']].values, ev_id)\n",
    "\n",
    "    return graph_with_inds\n",
    "\n",
    "\n",
    "from ariadne.graph_net.dataset import collate_fn\n",
    "\n",
    "N_STATIONS = 35\n",
    "from timeit import default_timer as timer\n",
    "def eval_event(tgt_graph, model_g):\n",
    "    batch_input, batch_target = collate_fn([tgt_graph])\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_g(batch_input['inputs']).numpy().flatten() > 0.15\n",
    "\n",
    "    v1v2v3 = tgt_graph.v1v2v3 [ y_pred ]\n",
    "\n",
    "    def find_next( arr, processed):\n",
    "        ind = np.where(np.all(v1v2v3[:, :-1] == arr[-2:], axis=1))\n",
    "        v_next = v1v2v3[ind]\n",
    "        if len(v_next) > 0: return find_next(np.append(arr, v_next[0][-1]), np.append(processed, ind))\n",
    "        else: return (np.array([arr]), processed)\n",
    "\n",
    "    v_all = None\n",
    "\n",
    "    while v1v2v3.size != 0:\n",
    "\n",
    "        v, processed = find_next(v1v2v3[0], np.array([0]))\n",
    "\n",
    "        v1v2v3 = np.delete(v1v2v3, processed, 0)\n",
    "\n",
    "        if v.size != N_STATIONS: continue\n",
    "\n",
    "        if v_all is None: v_all = v\n",
    "        else:\n",
    "            v_all = np.concatenate((v_all, v))\n",
    "\n",
    "    eval_df = pd.DataFrame( v_all,columns=[f\"hit_id_{n}\" for n in range(1,N_STATIONS+1)])\n",
    "\n",
    "    eval_df[ [f\"hit_id_{n}\" for n in range(1,N_STATIONS+1)]] = v_all\n",
    "\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "evaluator = EventEvaluator(parse_cfg, global_transformer, N_STATIONS)\n",
    "events = evaluator.prepare(model_loader=GraphModelLoader())[0]\n",
    "all_results = evaluator.build_all_tracks()\n",
    "model_results = evaluator.run_model(get_graph, eval_event)\n",
    "results_graphnet = evaluator.solve_results(model_results, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637e1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
