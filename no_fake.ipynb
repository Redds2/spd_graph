{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebe9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_8788\\1635990592.py:11: DeprecationWarning: Importing clear_output from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output, display\n",
      "C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_8788\\1635990592.py:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output, display\n",
      "Exception when trying to get git hash... bad!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read entry 40e9592622269c671734f2bb8c0c139c hit\n",
      "[prepare]: started processing a df output1000.tsv with 17413 rows:\n",
      "read entry 7faa83992f347bbebed5569eb51272b2 hit\n",
      "[prepare] finished\n",
      "[prepare] loading your model(s)...\n",
      "[prepare] finished loading your model(s)...\n",
      "[build_all_tracks] start\n",
      "read entry d988ad80694d0d4841883c67c133e2b0 hit\n",
      "read entry fde3c49db41ad38a3ae36cfaec5090f6 hit\n",
      "\n",
      "\n",
      "processed: 99: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.41it/s]\n",
      "[build_all_tracks] cache miss, finish\n",
      "[run model] start\n",
      "read entry 1ede558889ebca29f4348f4b9d3eccde hit\n",
      "read entry 0dc313d1b4e8ef733464eea9fb8692e6 hit\n",
      "\n",
      "\n",
      "processed: 7:   8%|██████████████▏                                                                                                                                                                  | 8/100 [00:29<06:19,  4.13s/it]f\n",
      "processed: 9:  10%|█████████████████▌                                                                                                                                                              | 10/100 [00:38<06:11,  4.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DropEmpty returned empty data. Skipping all further transforms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got exception for preprocessing:\n",
      " message=Traceback (most recent call last):\n",
      "  File \"D:\\ariadne_master_clean\\ariadne-master\\eval\\event_evaluation.py\", line 123, in run_model\n",
      "    preprocess_result = model_preprocess_func(event_df)\n",
      "  File \"C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_8788\\1635990592.py\", line 133, in get_graph\n",
      "    event = event[['event', 'r', 'phi', 'z', 'station', 'track']]\n",
      "  File \"D:\\miniconda\\envs\\ariadne_cpu\\lib\\site-packages\\pandas\\core\\frame.py\", line 3511, in __getitem__\n",
      "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
      "  File \"D:\\miniconda\\envs\\ariadne_cpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5782, in _get_indexer_strict\n",
      "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
      "  File \"D:\\miniconda\\envs\\ariadne_cpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5845, in _raise_if_missing\n",
      "    raise KeyError(f\"{not_found} not in index\")\n",
      "KeyError: \"['r', 'phi'] not in index\"\n",
      " \n",
      "                                            on \n",
      "event_id=9\n",
      "processed: 99: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [06:54<00:00,  4.14s/it]\n",
      "[run model] cache miss, finish\n",
      "[solve results] start\n",
      "[solve results] finish\n",
      "[solve results] final stats:\n",
      "==========EVALUATION RESULTS==========\n",
      "Total events evaluated: 100\n",
      "Total tracks evaluated: 501\n",
      "Track Efficiency (recall): 0.8822 \n",
      "Track Purity (precision): 0.9228 \n",
      "Fully reconstructed event ratio: 0.7000\n",
      "Mean cpu time per event: 4.1610 sec (0.24 events per second) \n",
      "Mean gpu time per event: 0.0159 sec (63.02 events per second) \n",
      "==========EVALUATION RESULTS==========\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from IPython.core.display import clear_output, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "from eval.event_evaluation import EventEvaluator\n",
    "from ariadne_v2.transformations import Compose, ConstraintsNormalize, ToCylindrical, DropSpinningTracks, DropShort, \\\n",
    "    DropEmpty\n",
    "\n",
    "parse_cfg = {\n",
    "    'csv_params': {\n",
    "        \"sep\": '\\s+',\n",
    "        # \"nrows\": 15000,\n",
    "        \"encoding\": 'utf-8',\n",
    "        \"names\": ['event', 'x', 'y', 'z', 'station', 'track', 'px', 'py', 'pz', 'X0', 'Y0', 'Z0']\n",
    "    },\n",
    "\n",
    "    'input_file_mask': \"D:/ariadne-master/output1000.tsv\",\n",
    "    'events_quantity': '0..100'\n",
    "}\n",
    "\n",
    "global_transformer = Compose([\n",
    "    DropSpinningTracks(),\n",
    "    DropShort(num_stations=3),\n",
    "    DropEmpty()\n",
    "])\n",
    "\n",
    "import scripts.clean_cache\n",
    "\n",
    "# to clean cache if needed\n",
    "# scripts.clean_cache.clean_jit_cache('20d')\n",
    "\n",
    "\n",
    "from ariadne.graph_net.graph_utils.graph_prepare_utils import to_pandas_graph_from_df, get_pd_line_graph, \\\n",
    "    apply_nodes_restrictions, apply_edge_restriction, construct_output_graph\n",
    "from ariadne.transformations import Compose, ConstraintsNormalize, ToCylindrical\n",
    "\n",
    "from ariadne_v2.inference import IModelLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "suff_df = ('_p', '_c')\n",
    "gin.bind_parameter('get_pd_line_graph.restrictions_0', (-2., 2.))\n",
    "gin.bind_parameter('get_pd_line_graph.restrictions_1', (-0.03, 0.03))\n",
    "gin.bind_parameter('get_pd_line_graph.suffix_c', '_c')\n",
    "gin.bind_parameter('get_pd_line_graph.suffix_p', '_p')\n",
    "gin.bind_parameter('get_pd_line_graph.spec_kwargs', {'suffix_c': '_c',\n",
    "                                                     'suffix_p': '_p',\n",
    "                                                     'axes': ['r', 'phi', 'z']})\n",
    "_edge_restriction = 0.15\n",
    "\n",
    "\n",
    "class GraphModelLoader(IModelLoader):\n",
    "    def __call__(self):\n",
    "        from ariadne.graph_net.model import GraphNet_v1\n",
    "        import torch\n",
    "\n",
    "        gin.bind_parameter('GraphNet_v1.input_dim', 5)\n",
    "        gin.bind_parameter('GraphNet_v1.hidden_dim', 128)\n",
    "        gin.bind_parameter('GraphNet_v1.n_iters', 1)\n",
    "\n",
    "        def weights_update_g(model, checkpoint):\n",
    "            model_dict = model.state_dict()\n",
    "            pretrained_dict = checkpoint['state_dict']\n",
    "            real_dict = {}\n",
    "            for (k, v) in model_dict.items():\n",
    "                needed_key = None\n",
    "                for pretr_key in pretrained_dict:\n",
    "                    if k in pretr_key:\n",
    "                        needed_key = pretr_key\n",
    "                        break\n",
    "                assert needed_key is not None, \"key %s not in pretrained_dict %r!\" % (k, pretrained_dict.keys())\n",
    "                real_dict[k] = pretrained_dict[needed_key]\n",
    "\n",
    "            model.load_state_dict(real_dict)\n",
    "            model.eval()\n",
    "            return model\n",
    "\n",
    "        path_g =  'D:/ariadne-master/lightning_logs/GraphNet_v1/version_120/epoch=19-step=3999.ckpt'\n",
    "\n",
    "        checkpoint_g = torch.load(path_g) if torch.cuda.is_available() else torch.load(path_g,\n",
    "                                                                                       map_location=torch.device('cpu'))\n",
    "        model_g = weights_update_g(model=GraphNet_v1(),\n",
    "                                   checkpoint=checkpoint_g)\n",
    "        model_hash = {\"path_g\": path_g, 'gin': gin.config_str(), 'model': '%r' % model_g, 'edge': _edge_restriction}\n",
    "        return model_hash, model_g\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "GraphWithIndices = namedtuple('Graph', ['X', 'Ri', 'Ro', 'y', 'v1v2v3', 'ev_id'])\n",
    "\n",
    "\n",
    "transformer_g = Compose([\n",
    "    DropSpinningTracks(),\n",
    "    DropShort(),\n",
    "    DropEmpty(),\n",
    "    ToCylindrical(),\n",
    "    ConstraintsNormalize(\n",
    "        columns=('r', 'phi', 'z'),\n",
    "        constraints={'r': [269., 581.], 'phi': [-3.15, 3.15], 'z': [-2386.0, 2386.0]},\n",
    "        use_global_constraints=True\n",
    "    ),\n",
    "])\n",
    "\n",
    "def construct_graph_with_indices(graph, v1v2v3, ev_id):\n",
    "    return GraphWithIndices(graph.X, graph.Ri, graph.Ro, graph.y, v1v2v3, ev_id)\n",
    "\n",
    "\n",
    "def get_graph(event):\n",
    "    event = event[['event', 'x', 'y', 'z', 'station', 'track', 'index_old']]\n",
    "\n",
    "    try:\n",
    "        event = transformer_g(event)\n",
    "    except AssertionError as err:\n",
    "        print(\"ASS error %r\" % err)\n",
    "        return None\n",
    "\n",
    "    event.index = event['index_old'].values\n",
    "    event = event[['event', 'r', 'phi', 'z', 'station', 'track']]\n",
    "\n",
    "    G = to_pandas_graph_from_df(event, suffixes=suff_df, compute_is_true_track=True)\n",
    "\n",
    "    nodes_t, edges_t = get_pd_line_graph(G, apply_nodes_restrictions)\n",
    "\n",
    "    edges_filtered = apply_edge_restriction(edges_t, edge_restriction=_edge_restriction)\n",
    "    graph = construct_output_graph(nodes_t, edges_filtered, ['y_p', 'y_c', 'z_p', 'z_c', 'z'],\n",
    "                                   [np.pi, np.pi, 1., 1., 1.], 'edge_index_p', 'edge_index_c')\n",
    "    ev_id = event.event.values[0]\n",
    "    graph_with_inds = construct_graph_with_indices(graph,\n",
    "                                                   edges_filtered[['from_ind', 'cur_ind', 'to_ind']].values, ev_id)\n",
    "\n",
    "    return graph_with_inds\n",
    "\n",
    "\n",
    "from ariadne.graph_net.dataset import collate_fn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TKAgg')\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "N_STATIONS = 35\n",
    "from timeit import default_timer as timer\n",
    "def eval_event(tgt_graph, model_g,start_fin_ind):\n",
    "    batch_input, batch_target = collate_fn([tgt_graph])\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_g(batch_input['inputs']).numpy().flatten() > 0.15\n",
    "\n",
    "    v1v2v3 = tgt_graph.v1v2v3 [ y_pred ]\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for v in v1v2v3:\n",
    "        G.add_edge(v[0], v[1])\n",
    "        G.add_edge(v[1], v[2])\n",
    "\n",
    "    v_all = None\n",
    "    excluded = []\n",
    "    for start_hit in start_fin_ind[0]:\n",
    "        for fin_hit in start_fin_ind[1]:\n",
    "\n",
    "            if fin_hit in excluded: continue\n",
    "            if start_hit in G and fin_hit in G and nx.has_path(G,start_hit,fin_hit):\n",
    "\n",
    "                v = nx.shortest_path(G, start_hit, fin_hit) #[ v for v in nx.all_simple_paths(G, start_hit, fin_hit) if len(v) == N_STATIONS  ]\n",
    "                #print(v)\n",
    "                #if len(v) > 0:\n",
    "                if len(v) == N_STATIONS:\n",
    "                    excluded.append(fin_hit)\n",
    "                    #[ G.remove_nodes_from(v_) for v_ in v]\n",
    "                    G.remove_nodes_from(v)\n",
    "                    if v_all is None:\n",
    "                        v_all = np.array([v])\n",
    "                    else:\n",
    "                        v_all = np.concatenate((v_all, np.array([v]) ), axis=0)\n",
    "\n",
    "   \n",
    "    eval_df = pd.DataFrame(v_all, columns=[f\"hit_id_{n}\" for n in range(1, N_STATIONS + 1)])\n",
    "\n",
    "    eval_df[ [f\"hit_id_{n}\" for n in range(1,N_STATIONS+1)]] = v_all\n",
    "\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "evaluator = EventEvaluator(parse_cfg, global_transformer, N_STATIONS)\n",
    "events = evaluator.prepare(model_loader=GraphModelLoader())[0]\n",
    "all_results = evaluator.build_all_tracks()\n",
    "model_results = evaluator.run_model(get_graph, eval_event)\n",
    "results_graphnet = evaluator.solve_results(model_results, all_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02b77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
